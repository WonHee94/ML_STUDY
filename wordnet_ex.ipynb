{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/87/76e691bbf1759ad6af5831649aae6a8d2fa184a1bcc71018ca6300399e5f/nltk-3.2.5.tar.gz (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 258kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in ./anaconda3/lib/python3.7/site-packages (from nltk==3.2.5) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.2.5-cp37-none-any.whl size=1392142 sha256=3c073b7272390aa29bfe872e772ef8efa622769a35a074b73f895b6b9fa583ed\n",
      "  Stored in directory: /home/wonhee/.cache/pip/wheels/da/8c/38/a8a36581975f8d03275c49960019f955e4d19fd14ae7e42d3d\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Found existing installation: nltk 3.4.4\n",
      "    Uninstalling nltk-3.4.4:\n",
      "      Successfully uninstalled nltk-3.4.4\n",
      "Successfully installed nltk-3.2.5\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 19.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk==3.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wonhee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypernyms(word):\n",
    "    current_node = wn.synsets(word)[0]\n",
    "    yield current_node\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            current_node = current_node.hypernyms()[0]\n",
    "            yield current_node\n",
    "        except IndexError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('policeman.n.01')\n",
      "Synset('lawman.n.01')\n",
      "Synset('defender.n.01')\n",
      "Synset('preserver.n.03')\n",
      "Synset('person.n.01')\n",
      "Synset('causal_agent.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "for h in hypernyms('policeman'):\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('fireman.n.04'),\n",
       " Synset('defender.n.01'),\n",
       " Synset('preserver.n.03'),\n",
       " Synset('person.n.01'),\n",
       " Synset('causal_agent.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h for h in hypernyms('firefighter')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('sheriff.n.01'),\n",
       " Synset('lawman.n.01'),\n",
       " Synset('defender.n.01'),\n",
       " Synset('preserver.n.03'),\n",
       " Synset('person.n.01'),\n",
       " Synset('causal_agent.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h for h in hypernyms('sheriff')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('mailman.n.01'),\n",
       " Synset('deliveryman.n.01'),\n",
       " Synset('employee.n.01'),\n",
       " Synset('worker.n.01'),\n",
       " Synset('person.n.01'),\n",
       " Synset('causal_agent.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h for h in hypernyms('mailman')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance(word1, word2):\n",
    "    word1_hypernyms = [h for h in hypernyms(word1)]\n",
    "    \n",
    "    for i, word2_hypernym in enumerate(hypernyms(word2)):\n",
    "        try:\n",
    "            return i + word1_hypernyms.index(word2_hypernym)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "distance('sheriff', 'student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance(word1, word2):\n",
    "    word1_hypernyms = [h for h in hypernyms(word1)]\n",
    "    \n",
    "    for i, word2_hypernym in enumerate(hypernyms(word2)):\n",
    "        try:\n",
    "            return i + word1_hypernyms.index(word2_hypernym)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "distance('sheriff', 'policeman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.791759469228055\n",
      "-0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def similarity(word1, word2):\n",
    "    return -np.log(distance(word1, word2))\n",
    "\n",
    "print(similarity('sheriff', 'student'))\n",
    "print(similarity('sheriff', 'policeman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
